<!-- This comment will put IE 6, 7 and 8 in quirks mode -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- CI hack NOve,ber 9, 2017 -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>include/shark/Algorithms/Trainers/Budgeted/MergeBudgetMaintenanceStrategy.h Source File</title>
<script type="text/javaScript" src="$relpath/search.js"></script>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
        MathJax.Ajax.timeout = 5000;  <!-- 5 second rather than 15 seconds timeout for file access -->
        <!-- ( nicked from https://groups.google.com/forum/#!msg/mathjax-users/HKA2lNqv-OQ/_Yv72L7MtjYJ ) -->
</script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntilConfig">
</script>
<script src="../../mlstyle.js"></script>
<!-- nicked from https://groups.google.com/forum/#!msg/mathjax-users/J-36V22-G9Q/AW3ncCbJzS8J -->
<link href="../css/besser.css" rel="stylesheet" type="text/css"/>
</head>
<!-- pretty cool: each body gets an id tag which is the basename of the web page  -->
<!--              and allows for page-specific CSS. this is client-side scripted, -->
<!--              so the id will not yet show up in the served source code -->
<script type="text/javascript">
    jQuery(document).ready(function () {
        var url = jQuery(location).attr('href');
        var pname = url.substr(url.lastIndexOf("/")+1, url.lastIndexOf(".")-url.lastIndexOf("/")-1);
        jQuery('#this_url').html('<strong>' + pname + '</strong>');
        jQuery('body').attr('id', pname);
    });
</script>
<body>
    <div id="shark_old">
        <div id="wrap">
            <div id="header">
                <div id="site-name"><a href="../../sphinx_pages/build/html/index.html">Shark machine learning library</a></div>
                <ul id="nav">
                    <li >
                        <a href="../../sphinx_pages/build/html/rest_sources/installation.html">Installation</a>
                    </li>
		    <li >
                        <a href="../../sphinx_pages/build/html/rest_sources/tutorials/tutorials.html">Tutorials</a>
                    </li>
		    <li >
                        <a href="../../sphinx_pages/build/html/rest_sources/benchmark.html">Benchmarks</a>
                    </li>
                    <li class="active">
                        <a href="classes.html">Documentation</a>
                        <ul>
                            <li class="first"></li>
                            <li><a href="../../sphinx_pages/build/html/rest_sources/quickref/quickref.html">Quick references</a></li>
                            <li><a href="classes.html">Class list</a></li>
                            <li class="last"><a href="group__shark__globals.html">Global functions</a></li>
                        </ul>
                    </li>
                </ul>
            </div>
        </div>
    </div>
<div id="doxywrapper">
<!--
    <div id="global_doxytitle">Doxygen<br>Documentation:</div>
-->
    <div id="navrow_wrapper">
<!-- Generated by Doxygen 1.8.14 -->
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_9d0c4981f10d03078bcfd5c74fe41ce8.html">shark</a></li><li class="navelem"><a class="el" href="dir_24fc231769ada4cfc8add7cd238ad0f8.html">Algorithms</a></li><li class="navelem"><a class="el" href="dir_d6773070a94f7c70aee2dbd98ae019ea.html">Trainers</a></li><li class="navelem"><a class="el" href="dir_35bc3b4a2ecbb7d544133e12b9e7d915.html">Budgeted</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">MergeBudgetMaintenanceStrategy.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="_merge_budget_maintenance_strategy_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===========================================================================</span><span class="comment"></span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">/*!</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * \brief       Merge budget maintenance strategy</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * \par</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * This is an budget strategy that adds a new vector by merging</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> * a pair of budget vectors. The pair to merge is found by first</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> * searching for the budget vector with the smallest alpha-coefficients</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"> * (measured in 2-norm), and then finding the second one by</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"> * computing a certain degradation measure. This is therefore linear</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"> * in the size of the budget.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"> * \par</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"> * The method is an implementation of the merge strategy</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"> * given in wang, crammer, vucetic: &quot;Breaking the Curse of Kernelization:</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment"> * Budgeted Stochastic Gradient Descent for Large-Scale SVM Training&quot;</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment"> * and owes very much to the implementation in BudgetedSVM.</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment"> * \author      Aydin Demircioglu</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment"> * \date        2014</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment"> * \par Copyright 1995-2017 Shark Development Team</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment"> * &lt;BR&gt;&lt;HR&gt;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment"> * This file is part of Shark.</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment"> * &lt;http://shark-ml.org/&gt;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment"> * Shark is free software: you can redistribute it and/or modify</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment"> * it under the terms of the GNU Lesser General Public License as published</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment"> * by the Free Software Foundation, either version 3 of the License, or</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment"> * (at your option) any later version.</span></div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment"> * Shark is distributed in the hope that it will be useful,</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment"> * but WITHOUT ANY WARRANTY; without even the implied warranty of</span></div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment"> * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment"> * GNU Lesser General Public License for more details.</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="comment"> * You should have received a copy of the GNU Lesser General Public License</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="comment"> * along with Shark.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="comment">//===========================================================================</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="preprocessor">#ifndef SHARK_MODELS_MERGEBUDGETMAINTENANCESTRATEGY_H</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="preprocessor">#define SHARK_MODELS_MERGEBUDGETMAINTENANCESTRATEGY_H</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="_line_search_8h.html">shark/Algorithms/GradientDescent/LineSearch.h</a>&gt;</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="_dataset_8h.html">shark/Data/Dataset.h</a>&gt;</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="_data_view_8h.html">shark/Data/DataView.h</a>&gt;</span></div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="_abstract_kernel_function_8h.html" title="abstract super class of all kernel functions ">shark/Models/Kernels/AbstractKernelFunction.h</a>&gt;</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="_abstract_budget_maintenance_strategy_8h.html">shark/Algorithms/Trainers/Budgeted/AbstractBudgetMaintenanceStrategy.h</a>&gt;</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceshark.html" title="AbstractMultiObjectiveOptimizer. ">shark</a></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;{</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">/// \brief Budget maintenance strategy that merges two vectors</span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment">/// \par This is an budget strategy that simply merges two budget vectors</span></div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">/// in order to make space for a new one. This is done by first searching</span></div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">/// for the budget vector that has smallest \f[ ||\alpha||_2\f] coefficient-- only</span></div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">/// then a second one is searched for, by inspecting the expected</span></div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">/// weight degradation after merging. The vector with smallest weight</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">/// degradation is the vector one should merge with the first one.</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">/// By this heuristic, the merging strategy has complexity \f[ \mathcal{O}(B) \f].</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">/// Compared with the projection strategy, merging should be faster, and stil</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">/// obtains similar accuracy. Unluckily any kind of timing numbers are missing</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">/// in the reference paper of Wang, Crammer and Vucetic.</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="comment">/// \par Note that in general it is unclear how two data objects should be merged,</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="comment">/// e.g. strings must be merged differently than vectors. Therefore it is necessary</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;<span class="comment">/// to create an specialization of this strategy for a given input type.</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment"></span><span class="keyword">template</span>&lt;<span class="keyword">class</span> InputType&gt;</div><div class="line"><a name="l00083"></a><span class="lineno"><a class="line" href="classshark_1_1_merge_budget_maintenance_strategy.html">   83</a></span>&#160;<span class="keyword">class </span><a class="code" href="classshark_1_1_merge_budget_maintenance_strategy.html" title="Budget maintenance strategy that merges two vectors. ">MergeBudgetMaintenanceStrategy</a>: <span class="keyword">public</span> <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html" title="This is the abstract interface for any budget maintenance strategy. ">AbstractBudgetMaintenanceStrategy</a>&lt;InputType&gt;{};</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment">/// \brief Budget maintenance strategy merging vectors.</span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="comment">/// \par This is an specialization of the merge budget maintenance strategy</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment">/// that handles simple real-valued vectors. This is a nearly 1:1 adoption of</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment">/// the strategy presented in Wang, Cramer and Vucetic.</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment">///</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="comment"></span><span class="keyword">template</span>&lt;&gt;</div><div class="line"><a name="l00095"></a><span class="lineno"><a class="line" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html">   95</a></span>&#160;<span class="keyword">class </span><a class="code" href="classshark_1_1_merge_budget_maintenance_strategy.html" title="Budget maintenance strategy that merges two vectors. ">MergeBudgetMaintenanceStrategy</a>&lt;RealVector&gt;: <span class="keyword">public</span> <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html" title="This is the abstract interface for any budget maintenance strategy. ">AbstractBudgetMaintenanceStrategy</a>&lt;RealVector&gt;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;{</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classshark_1_1_kernel_expansion.html" title="Linear model in a kernel feature space. ">KernelExpansion&lt;RealVector&gt;</a> <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html#a2fce0a0656e77df1f5e54bea0d3c9f6b">ModelType</a>;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keyword">typedef</span> <a class="code" href="classshark_1_1_labeled_data.html" title="Data set for supervised learning. ">LabeledData&lt;RealVector, unsigned int&gt;</a> <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html#a7027102ef6150ec0de810886b8098718">DataType</a>;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <span class="keyword">typedef</span> RealVector <a class="code" href="_multi_task_svm_8cpp.html#a0dea9a3a85d327080d9b617903508925">InputType</a>;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;<span class="comment">    /// This is the objective function we need to optimize during merging.</span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment">    /// Basically the merging strategy needs a line search to find the parameter</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">    /// which maximizes \f[ a \cdot k_h (x_m, x_n) + b \cdot k_{1-h}(x_m, x_n) \f].</span></div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment">    /// (all in the notation of wang, crammer and vucetic).</span></div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment">    /// The coefficients a and b  are given by the alpha coefficients of the</span></div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="comment">    /// corresponding support vectors  \f[ x_m \f] and  \f[ x_n\f], more precicely</span></div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;<span class="comment">    /// we have \f[ a = \sum \alpha_m^{(i)}/d_i\f] and \f[b = 1 - a = \sum \alpha_n^{(i)}/d_i\f]</span></div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment">    /// with \f[d_i = \alpha_m^{(i)} + \alpha_n^{(i)} \f].</span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">    ///</span></div><div class="line"><a name="l00112"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html">  112</a></span>&#160;<span class="comment"></span>    <span class="keyword">struct </span>MergingProblemFunction : <span class="keyword">public</span> <a class="code" href="classshark_1_1_abstract_objective_function.html">SingleObjectiveFunction</a></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;    {</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a7644115fbbb1839032ab05a546c1d9fe">  114</a></span>&#160;        <span class="keyword">typedef</span> <a class="code" href="classshark_1_1_abstract_objective_function.html">SingleObjectiveFunction</a> <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a7644115fbbb1839032ab05a546c1d9fe">Base</a>;</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="comment">        /// class name</span></div><div class="line"><a name="l00117"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a2dfbff2e4e5b3e6015b2964069f65fe3">  117</a></span>&#160;<span class="comment"></span>        std::string <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a2dfbff2e4e5b3e6015b2964069f65fe3" title="class name ">name</a>()<span class="keyword"> const</span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="keyword">        </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;MergingProblemFunction&quot;</span>; }</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="comment">        /// parameters for the function.</span></div><div class="line"><a name="l00122"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a1553e03dffa8dcca196a26b40d477cbe">  122</a></span>&#160;<span class="comment"></span>        <span class="keywordtype">double</span> m_a, <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a1553e03dffa8dcca196a26b40d477cbe">m_b</a>;</div><div class="line"><a name="l00123"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a6504381c0a6c3b2267ad5093dd6c5140">  123</a></span>&#160;        <span class="keywordtype">double</span> <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a6504381c0a6c3b2267ad5093dd6c5140">m_k</a>; <span class="comment">//&lt; contains (in our problem) k(x_m, x_n)</span></div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;<span class="comment">        /// constructor.</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;<span class="comment">        /// \param[in] a    a coefficient of the formula</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="comment">        /// \param[in] b    b coefficient of the formula</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="comment">        /// \param[in] k    k coefficient of the formula</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment">        ///</span></div><div class="line"><a name="l00131"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a5ab2639b70356a5165bffd26702bc058">  131</a></span>&#160;<span class="comment"></span>        <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a5ab2639b70356a5165bffd26702bc058">MergingProblemFunction</a>(<span class="keywordtype">double</span> a, <span class="keywordtype">double</span> b, <span class="keywordtype">double</span> k)</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        {</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;            m_a = a;</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;            m_b = b;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;            m_k = k;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        }</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment">        /// number of variables, we have a one-dimensional problem here.</span></div><div class="line"><a name="l00140"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a5643027ade6dc7961b582b3545fa8338">  140</a></span>&#160;<span class="comment"></span>        std::size_t <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a5643027ade6dc7961b582b3545fa8338" title="number of variables, we have a one-dimensional problem here. ">numberOfVariables</a>()<span class="keyword">const</span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;            <span class="keywordflow">return</span> 1;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        }</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="comment">        /// evaluation</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;<span class="comment">        /// \param[in]  pattern      vector to evaluate the function at. as we have a 1d problem,</span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment">        ///                                         we ignore everything beyond the first component.</span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment">        /// \return function value at the point</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment">        ///</span></div><div class="line"><a name="l00151"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a0674c4dae609a1c36929fe77e6c871c8">  151</a></span>&#160;<span class="comment"></span>        <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a0674c4dae609a1c36929fe77e6c871c8">eval</a>(RealVector <span class="keyword">const</span>&amp; pattern)<span class="keyword">const</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;            <span class="keywordtype">double</span> h = pattern(0);</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;            <span class="comment">// we want to maximize, thus minimize   -function</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;            <span class="keywordflow">return</span> (- (m_a * pow(m_k, (1.0 - h) * (1.0 - h)) + m_b * pow(m_k, h * h)));</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;        }</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment">        /// Derivative of function.</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment">        /// Unsure if the derivative is really needed, but wolfram alpha</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment">        /// helped computing it, do not want to let it down, wasting its capacity.</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment">        /// The search routine uses it, as we did not removed the derivative-feature.</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment">        /// \param[in]  input   Point to evaluate the function at</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment">        /// \param[out] derivative  Derivative at the given point</span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment">        /// \return     Function value at the point</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment">        ///</span></div><div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a065cb2154a49e6948f7d6a59cf2cd49c">  167</a></span>&#160;<span class="comment"></span>        <span class="keyword">virtual</span> <span class="keywordtype">double</span> <a class="code" href="structshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4_1_1_merging_problem_function.html#a065cb2154a49e6948f7d6a59cf2cd49c">evalDerivative</a>(<span class="keyword">const</span> <a class="code" href="classshark_1_1_abstract_objective_function.html#a59bfea031628e16737c66e7117eba7b5">SearchPointType</a> &amp; input, <a class="code" href="classshark_1_1_abstract_objective_function.html#a37a8dfc61d972d0358bda3d35c79bf96">FirstOrderDerivative</a> &amp; derivative)<span class="keyword">const</span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="keyword">        </span>{</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;            <span class="keywordtype">double</span> h = input(0);</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;            <span class="comment">// we want to maximize, thus minimize   -function</span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;            derivative(0) = 2 * log(m_k) * (-m_a * (h - 1.0) * pow(m_k, (h - 1.0) * (h - 1.0))</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;                                            - m_b * h * pow(m_k, (h * h)));</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;            <span class="keywordflow">return</span> eval(input);</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        }</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;    };</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment">    /// Reduce the budget.</span></div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment">    /// This is a helper routine. after the addToModel adds the new support vector</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">    /// to the end of the budget (it was chosen one bigger than the capacity),</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment">    /// this routine will do the real merging. Given a index it will search for a second</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;<span class="comment">    /// index, so that merging is &#39;optimal&#39;. It then will perform the merging. After that</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;<span class="comment">    /// the last budget vector will be freed again (by setting its alpha-coefficients to zero).</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="comment">    /// \param[in]  model   Model to work on</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment">    /// \param[in]  firstIndex  The index of the first element of the pair to merge.</span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment">    ///</span></div><div class="line"><a name="l00188"></a><span class="lineno"><a class="line" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#a50f9819caf20e6bedad5e6735e5db2e0">  188</a></span>&#160;<span class="comment"></span>    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#a50f9819caf20e6bedad5e6735e5db2e0">reduceBudget</a>(<a class="code" href="classshark_1_1_kernel_expansion.html" title="Linear model in a kernel feature space. ">ModelType</a>&amp; model, <span class="keywordtype">size_t</span> firstIndex)</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    {</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;        <span class="keywordtype">size_t</span> maxIndex = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga814e8b0028cc90dd2af69805e8f8a04d" title="Returns the total number of elements. ">numberOfElements</a>();</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        <span class="comment">// compute the kernel row of the given, first element and all the others</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        <span class="comment">// should take O(B) time, as it is a row of size B</span></div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;        blas::vector&lt;float&gt; kernelRow(maxIndex, 0.0);</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> j = 0; j &lt; maxIndex; j++)</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;            kernelRow(j) = <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>( model.<a class="code" href="classshark_1_1_kernel_expansion.html#a3155942d4a86c7ef501f36f35e2cd3b6">kernel</a>()-&gt;<a class="code" href="classshark_1_1_abstract_kernel_function.html#abd10e3815efade90c7f9e2a7cc8bcb6c" title="Evaluates the kernel function. ">eval</a>(model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(firstIndex), model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(j)));</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;        <span class="comment">// initialize the search</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        <span class="keywordtype">double</span> fret(0.);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        RealVector h(1);     <span class="comment">// initial search starting point</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;        RealVector xi(1);    <span class="comment">// direction of search</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;        RealVector d(1);    <span class="comment">// derivative ater line-search (not needed)</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;        <span class="comment">// save the parameter at the minimum</span></div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;        <span class="keywordtype">double</span> minDegradation = std::numeric_limits&lt;double&gt;::infinity();</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        <span class="keywordtype">double</span> minH = 0.0;</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;        <span class="keywordtype">double</span> minAlphaMergedFirst = 0.0;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;        <span class="keywordtype">double</span> minAlphaMergedSecond = 0.0;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;        <span class="keywordtype">size_t</span> secondIndex = 0;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;        <span class="comment">// we need to check every other vector</span></div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        RealMatrix &amp;alpha = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a7730f91f4f86957f8e095dfc190b2774">alpha</a>();</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> currentIndex = 0; currentIndex &lt; maxIndex; currentIndex++)</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;        {</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;            <span class="comment">// we do not want the vector already chosen</span></div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;            <span class="keywordflow">if</span>(firstIndex == currentIndex)</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;                <span class="keywordflow">continue</span>;</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;            <span class="comment">// compute the alphas for the model, this is the formula</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;            <span class="comment">// between (6.7) and (6.8) in wang, crammer, vucetic</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;            <span class="keywordtype">double</span> a = 0.0;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;            <span class="keywordtype">double</span> b = 0.0;</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> c = 0; c &lt; alpha.size2(); c++)</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;            {</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                <span class="keywordtype">double</span> d = std::min(0.00001, alpha(currentIndex, c) + alpha(firstIndex, c));</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;                a += alpha(firstIndex, c) / d;</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                b += alpha(currentIndex, c) / d;</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            }</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;            <span class="comment">// Initialize search starting point and direction:</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;            h(0) = 0.0;</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            xi(0) = 0.5;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;            <span class="keywordtype">double</span> k = kernelRow(currentIndex);</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;            MergingProblemFunction mergingProblemFunction(a, b, k);</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;            fret = mergingProblemFunction.evalDerivative(h,d);</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;            <span class="comment">//perform a line-search</span></div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;            <a class="code" href="classshark_1_1_line_search.html" title="Wrapper for the linesearch class of functions in the linear algebra library. ">LineSearch&lt;RealVector&gt;</a> lineSearch;</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;            lineSearch.<a class="code" href="classshark_1_1_line_search.html#aa6a5189c633cdb9afa68766fbf0e450e">lineSearchType</a>() = <a class="code" href="namespaceshark.html#a794f90d30bf600493abe8c1fb5cdbcc1a75f3b46c5979224eb3bf69483a46cf36">LineSearchType::Dlinmin</a>;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;            lineSearch.<a class="code" href="classshark_1_1_line_search.html#ab9c07455e28cb27e697909daba8005d5" title="initializes the internal state of the LineSearch class and sets the function on which the lineSearch ...">init</a>(mergingProblemFunction);</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;            lineSearch(h,fret,xi,d,1.0);</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;            <span class="comment">// the optimal point is now given by h.</span></div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;            <span class="comment">// the vector that corresponds to this is</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            <span class="comment">// $z = h x_m + (1-h) x_n$  by formula (6.7)</span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;            RealVector firstVector = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(firstIndex);</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;            RealVector currentVector = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(currentIndex);</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;            RealVector mergedVector = h(0) * firstVector + (1.0 - h(0)) * currentVector;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;            <span class="comment">// this is another minimization problem, which has as optimal</span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;            <span class="comment">// solution $\alpha_z^{(i)} = \alpha_m^{(i)} k(x_m, z) + \alpha_n^{(i)} k(x_n, z).$</span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;            <span class="comment">// the coefficient of this z is computed by approximating</span></div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;            <span class="comment">// both vectors by the merged one. maybe KernelBasisDistance can be used</span></div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;            <span class="comment">// but i am not sure, if at all and if, if its faster.</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;            <span class="keywordtype">long</span> <span class="keywordtype">double</span> alphaMergedFirst = pow(k, (1.0 - h(0)) * (1.0 - h(0)));</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;            <span class="keywordtype">long</span> <span class="keywordtype">double</span> alphaMergedCurrent = pow(k, h(0) * h(0));</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;            <span class="comment">// degradation is computed for each class</span></div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;            <span class="comment">// this is computed by using formula (6.8), applying it to each class and summing up</span></div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;            <span class="comment">// here a kernel with $k(x,x) = 1$ is assumed</span></div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;            <span class="keywordtype">double</span> currentDegradation = 0.0f;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> c = 0; c &lt; alpha.size2(); c++)</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;            {</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;                <span class="keywordtype">double</span> zAlpha = alphaMergedFirst * alpha(firstIndex, c) + alphaMergedCurrent * alpha(currentIndex, c);</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;                <span class="comment">// TODO: unclear to me why this is the thing we want to compute</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;                currentDegradation += pow(alpha(firstIndex, c), 2) + pow(alpha(currentIndex, c), 2) +</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;                                      2.0 * k * alpha(firstIndex, c) * alpha(currentIndex, c) - zAlpha * zAlpha;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;            }</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;            <span class="comment">// TODO: this is shamelessly copied, as the rest, but maybe i want to refactor it and make it nicer.</span></div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;            <span class="keywordflow">if</span>(currentDegradation &lt; minDegradation)</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;            {</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;                minDegradation = currentDegradation;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;                minH = h(0);</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;                minAlphaMergedFirst = alphaMergedFirst;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;                minAlphaMergedSecond = alphaMergedCurrent;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                secondIndex = currentIndex;</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;            }</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;        }</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;        <span class="comment">// compute merged vector</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;        RealVector firstVector = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(firstIndex);</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;        RealVector secondVector = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(secondIndex);</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;        RealVector mergedVector = minH * firstVector + (1.0 - minH) * secondVector;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;        <span class="comment">// replace the second vector by the merged one</span></div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(secondIndex) = mergedVector;</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;        <span class="comment">// and update the alphas</span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> c = 0; c &lt; alpha.size2(); c++)</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        {</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;            alpha(secondIndex, c) = minAlphaMergedFirst * alpha(firstIndex, c) + minAlphaMergedSecond * alpha(secondIndex, c);</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;        }</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        <span class="comment">// the first index is now obsolete, so we copy the</span></div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        <span class="comment">// last vector, which serves as a buffer, to this position</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;        row(alpha, firstIndex) = row(alpha, maxIndex - 1);</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;        model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(firstIndex) = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(maxIndex - 1);</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;        <span class="comment">// clear the  buffer by cleaning the alphas</span></div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;        <span class="comment">// finally the vectors we merged.</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        row(model.<a class="code" href="classshark_1_1_kernel_expansion.html#a7730f91f4f86957f8e095dfc190b2774">alpha</a>(), maxIndex - 1).clear();</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    }</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment">    /// add a vector to the model.</span></div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">    /// this will add the given vector to the model and merge the budget so that afterwards</span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment">    /// the budget size is kept the same. If the budget has a free entry anyway, no merging</span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">    /// will be performed, but instead the given vector is simply added to the budget.</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">    ///</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="comment">    /// @param[in,out]  model   the model the strategy will work with</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment">    /// @param[in]  alpha   alphas for the new budget vector</span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment">    /// @param[in]  supportVector the vector to add to the model by applying the maintenance strategy</span></div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment">    ///</span></div><div class="line"><a name="l00318"></a><span class="lineno"><a class="line" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#a26faf1b7720149479335a6cf8aeebb38">  318</a></span>&#160;<span class="comment"></span>    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#a26faf1b7720149479335a6cf8aeebb38">addToModel</a>(<a class="code" href="classshark_1_1_kernel_expansion.html" title="Linear model in a kernel feature space. ">ModelType</a>&amp; model, InputType <span class="keyword">const</span>&amp; alpha, <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html#a4e4e18bcc754402146beb894a7c3d7cd">ElementType</a> <span class="keyword">const</span>&amp; supportVector)</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    {</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;        <span class="comment">// find the two indicies we want to merge</span></div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;        <span class="comment">// note that we have to crick ourselves, as the model has</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;        <span class="comment">// a fixed size, but actually we want to work with the model</span></div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;        <span class="comment">// together with the new supportvector. so our budget size</span></div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;        <span class="comment">// is one greater than the user specified and we use this</span></div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;        <span class="comment">// last entry of the model for buffer. it will be freed again,</span></div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;        <span class="comment">// when merging is finished.</span></div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;        <span class="comment">// put the new vector into place</span></div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;        <span class="keywordtype">size_t</span> maxIndex = model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga814e8b0028cc90dd2af69805e8f8a04d" title="Returns the total number of elements. ">numberOfElements</a>();</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;        model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(maxIndex - 1) = supportVector.input;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;        row(model.<a class="code" href="classshark_1_1_kernel_expansion.html#a7730f91f4f86957f8e095dfc190b2774">alpha</a>(), maxIndex - 1) = alpha;</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;        <span class="comment">// the first vector to merge is the one with the smallest alpha coefficient</span></div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;        <span class="comment">// (it cannot be our new vector, because in each iteration the</span></div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;        <span class="comment">// old weights get downscaled and the new ones get the biggest)</span></div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;        <span class="keywordtype">size_t</span> firstIndex = 0;</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;        <span class="keywordtype">double</span> firstAlpha = 0;</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;        <a class="code" href="classshark_1_1_abstract_budget_maintenance_strategy.html#ab6ab9d070c0988b041e96e66888a1841">findSmallestVector</a>(model, firstIndex, firstAlpha);</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;        <span class="comment">// if the smallest vector has zero alpha,</span></div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;        <span class="comment">// the budget is not yet filled so we can skip merging it.</span></div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        <span class="keywordflow">if</span>(firstAlpha == 0.0f)</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        {</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;            <span class="comment">// as we need the last vector to be zero, we put the new</span></div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;            <span class="comment">// vector to that place and undo our putting-the-vector-to-back-position</span></div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;            model.<a class="code" href="classshark_1_1_kernel_expansion.html#a06b25c0194b19a2e96b58433867dea5e">basis</a>().<a class="code" href="group__shark__globals.html#ga0ea72a74a21d5ff59772516b83c4a58b">element</a>(firstIndex) = supportVector.input;</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;            row(model.<a class="code" href="classshark_1_1_kernel_expansion.html#a7730f91f4f86957f8e095dfc190b2774">alpha</a>(), firstIndex) = alpha;</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            <span class="comment">// enough to zero out the alpha</span></div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;            row(model.<a class="code" href="classshark_1_1_kernel_expansion.html#a7730f91f4f86957f8e095dfc190b2774">alpha</a>(), maxIndex - 1).clear();</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;            <span class="comment">// ready.</span></div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;            <span class="keywordflow">return</span>;</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;        }</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        <span class="comment">// the second one is given by searching for the best match now,</span></div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;        <span class="comment">// taking O(B) time. we also have to provide to the findVectorToMerge</span></div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;        <span class="comment">// function the supportVector we want to add, as we cannot, as</span></div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;        <span class="comment">// said, just extend the model with this vector.</span></div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        reduceBudget(model, firstIndex);</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;    }</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;<span class="comment">    /// class name</span></div><div class="line"><a name="l00368"></a><span class="lineno"><a class="line" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#aec9a14387771b164b93aeae8847995cf">  368</a></span>&#160;<span class="comment"></span>    std::string <a class="code" href="classshark_1_1_merge_budget_maintenance_strategy_3_01_real_vector_01_4.html#aec9a14387771b164b93aeae8847995cf" title="class name ">name</a>()<span class="keyword"> const</span></div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;<span class="keyword">    </span>{ <span class="keywordflow">return</span> <span class="stringliteral">&quot;MergeBudgetMaintenanceStrategy&quot;</span>; }</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;<span class="keyword">protected</span>:</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;};</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;}</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="preprocessor">#endif</span></div></div><!-- fragment --></div><!-- contents -->
</div>
</body>
</html>
