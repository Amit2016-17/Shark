
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Support Vector Machines: First Steps &#8212; Shark 3.0a documentation</title>
    <script type="text/x-mathjax-config">
        MathJax.Ajax.timeout = 5000;  <!-- 5 second rather than 15 seconds timeout for file access -->
        <!-- ( nicked from https://groups.google.com/forum/#!msg/mathjax-users/HKA2lNqv-OQ/_Yv72L7MtjYJ ) -->
    </script>
    <link rel="stylesheet" href="../../../_static/mt_sphinx_deriv.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntilConfig"></script>
    <link rel="shortcut icon" href="../../../_static/shark16.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search" href="svmModelSelection.html" />
    <link rel="prev" title="Random Forest" href="rf.html" />
    <link rel="stylesheet" href="../../../_static/mt_sphinx_shark.css" type="text/css" />
    <script type="text/javascript">
       window.MathJax || document.write('<script src="../../../index/../../../../../contrib/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntilConfig"><\/script>');
       <!--delay nicked from https://groups.google.com/forum/#!msg/mathjax-users/J-36V22-G9Q/AW3ncCbJzS8J -->
    </script>
    <script src="../../../index/../../../../mlstyle.js"></script>
    <!-- nicked from https://groups.google.com/forum/#!msg/mathjax-users/J-36V22-G9Q/AW3ncCbJzS8J -->

  </head><body>

    <div id="shark_old">
        <div id="wrap">
            <div id="header">
                <div id="site-name"><a href="/shark/index.html">Shark machine learning library</a></div>
                <ul id="nav">
                    <li  class="first" >
                        <a href="../../installation.html">Installation</a>
                    </li>
                    <li  class="active" >
                        <a href="../tutorials.html">Tutorials</a>
                    </li>
		    <li  class="first" >
                        <a href="../../benchmark.html">Benchmarks</a>
                    </li>
		    <li  class="first" >
                        <a href="../../../index/../../../../doxygen_pages/html/classes.html">Documentation</a>
                        <ul>
                            <li><a href="../../quickref/quickref.html">Quick references</a></li>
                            <li><a href="../../../index/../../../../doxygen_pages/html/classes.html">Class list</a></li>
                            <li class="last"><a href="../../../index/../../../../doxygen_pages/html/group__shark__globals.html">Global functions</a></li>
                        </ul>
                    </li>
                </ul>

            </div>
        </div>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
        <p class="logo"><a href="../../../index.html">
          <img class="logo" src="../../../_static/SharkLogo.png" alt="Logo"/></a></p>
	<div class="mt_ltocwrapper">
		<ul>
<li><a class="reference internal" href="#">Support Vector Machines: First Steps</a><ul>
<li><a class="reference internal" href="#theoretical-background">Theoretical background</a></li>
<li><a class="reference internal" href="#support-vector-machines-in-shark">Support Vector Machines in Shark</a></li>
<li><a class="reference internal" href="#full-example-program">Full example program</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

	</div>
<div>
  <a class="topless" href="rf.html" title="previous chapter">
	  <img class="navicon" src="../../../_static/icon_backward.png" alt="prev"/> Random Forest</a>
  <a class="topless" href="svmModelSelection.html" title="next chapter">
	  <img class="navicon" src="../../../_static/icon_forward.png" alt="next"/> Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search</a>
</div> 
<div id="searchbox" style="display: none">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" size="12" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
      <input class="mtsubmitbutton" type="submit" value="Find" />
    </form>
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
<p class="mtshowsource">
  <a href="../../../_sources/rest_sources/tutorials/algorithms/svm.rst.txt"
           rel="nofollow"><img class="sourceicon" src="../../../_static/icon_eject.png" alt="prev"/> Show page source</a>
</p>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="support-vector-machines-first-steps">
<h1>Support Vector Machines: First Steps<a class="headerlink" href="#support-vector-machines-first-steps" title="Permalink to this headline">¶</a></h1>
<p>Kernel-based learning algorithms such as support vector machine (SVM,
<a class="reference internal" href="#cortesvapnik1995" id="id1">[CortesVapnik1995]</a>) classifiers mark the state-of-the art in pattern
recognition . They employ (Mercer) kernel functions to implicitly
define a metric feature space for processing the input data, that is,
the kernel defines the similarity between observations.  Kernel
methods are well understood theoretically and give excellent results
in practice. This tutorial explains how to train a standard
C-SVM.</p>
<div class="section" id="theoretical-background">
<h2>Theoretical background<a class="headerlink" href="#theoretical-background" title="Permalink to this headline">¶</a></h2>
<p>The general supervised learning problem can be stated as follows.
Given sample data <span class="math notranslate">\(S=\{(x_i,y_i)\,|\,1 \leq i \leq \ell\}\)</span> drawn from an
unknown distribution <span class="math notranslate">\(p\)</span> over <span class="math notranslate">\(X \times Y\)</span>, the goal of binary
classification is to infer a hypothesis <span class="math notranslate">\(h:X \to Y\)</span> that minimizes the
expected risk</p>
<div class="math notranslate">
\[R_p(h)= \int\limits_{X \times Y} L_{0-1}(y,h(x)) \, \text{d}
p(x,y) ,\]</div>
<p>where <span class="math notranslate">\(L_{0-1}(y,z)\)</span> is 0
if <span class="math notranslate">\(y=z\)</span> and 1 otherwise.</p>
<p>Support vector machines (SVMs, <a class="reference internal" href="#cortesvapnik1995" id="id2">[CortesVapnik1995]</a>) transfer the input
data to a feature space and perform linear classification in that space.
For a positive semi-definite kernel function <span class="math notranslate">\(k:X \times X \to\mathbb{R}\)</span>, consider the feature space
<span class="math notranslate">\(\mathcal H_k = {\text{span} \{k(x, \cdot) \,|\, x \in X\}}\)</span> and
function class <span class="math notranslate">\(\mathcal H_k^b = \{f = g + b\,|\, g \in \mathcal H_k, b\in \mathbb{R}\}\)</span>. The decision boundary induced by the sign of a
function <span class="math notranslate">\(f \in \mathcal H_k^b\)</span> is an affine hyperplane in <span class="math notranslate">\(\mathcal H_k\)</span>.
1-Norm Soft Margin C-SVMs find a solution to</p>
<div class="math notranslate">
\[\underset{f \in\mathcal H_k^b}{\text{minimize}}  \frac{1}{2} \|f\|_2^2 + C \sum_{i=1}^\ell L_{\text{hinge}}(y_i, f(x_i))\]</div>
<p>with loss function
<span class="math notranslate">\(L_{\text{hinge}}(y,f(x))=\max\{0, 1-(2y-1)f(x)\}\)</span> for
<span class="math notranslate">\(Y=\{0,1\}\)</span>.
The parameter <span class="math notranslate">\(C &gt;= 0\)</span>
controls the trade-off between reducing the empirical loss
<span class="math notranslate">\(L_{\text{hinge}}\)</span> and the complexity of the hypothesis <span class="math notranslate">\(\|.\|_2\)</span>
measured by its norm (neglecting the bias parameter <span class="math notranslate">\(b\)</span>).</p>
<p>Here we have adopted the Shark library convention of choosing
<span class="math notranslate">\(Y=\{0,1\}\)</span> instead of <span class="math notranslate">\(Y=\{-1,1\}\)</span>. The latter is the
common choice in the SVM literature. This explains the <span class="math notranslate">\(2y-1\)</span>
instead of a simple <span class="math notranslate">\(y\)</span> in the hinge loss definition.</p>
</div>
<div class="section" id="support-vector-machines-in-shark">
<h2>Support Vector Machines in Shark<a class="headerlink" href="#support-vector-machines-in-shark" title="Permalink to this headline">¶</a></h2>
<p>For this tutorial the following include files are needed:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;shark/Algorithms/Trainers/CSvmTrainer.h&gt; // the C-SVM trainer</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;shark/Models/Kernels/GaussianRbfKernel.h&gt; //the used kernel for the SVM</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;shark/ObjectiveFunctions/Loss/ZeroOneLoss.h&gt; //used for evaluation of the classifier</span><span class="cp"></span>
<span class="cp">#include</span> <span class="cpf">&lt;shark/Data/DataDistribution.h&gt; //includes small toy distributions</span><span class="cp"></span>
</pre></div>
</div>
<div class="section" id="toy-problem">
<h3>Toy problem<a class="headerlink" href="#toy-problem" title="Permalink to this headline">¶</a></h3>
<p>In this tutorial, we consider an artificial binary benchmark classification
problem shipped with the Shark library:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">ell</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span>     <span class="c1">// number of training data point</span>
<span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tests</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">;</span> <span class="c1">// number of test data points</span>

<span class="n">Chessboard</span> <span class="n">problem</span><span class="p">;</span> <span class="c1">// artificial benchmark data</span>
<span class="n">ClassificationDataset</span> <span class="n">training</span> <span class="o">=</span> <span class="n">problem</span><span class="p">.</span><span class="n">generateDataset</span><span class="p">(</span><span class="n">ell</span><span class="p">);</span>
<span class="n">ClassificationDataset</span> <span class="n">test</span> <span class="o">=</span> <span class="n">problem</span><span class="p">.</span><span class="n">generateDataset</span><span class="p">(</span><span class="n">tests</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="section" id="model-and-learning-algorithm">
<h3>Model and learning algorithm<a class="headerlink" href="#model-and-learning-algorithm" title="Permalink to this headline">¶</a></h3>
<p>To build an SVM, we need a <a class="reference external" href="../../../../../../doxygen_pages/html/structshark_1_1_kernel_classifier.html">KernelClassifier</a>  and an
<a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_c_svm_trainer.html">CSvmTrainer</a>.</p>
<p>To define our model, we have to choose a kernel function.  Here we
consider the standard Gaussian/RBF kernel</p>
<div class="math notranslate">
\[k(x,z) = \exp(\gamma\|x-z\|^2)\]</div>
<p>by writing:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">;</span>         <span class="c1">// kernel bandwidth parameter</span>

<span class="n">GaussianRbfKernel</span><span class="o">&lt;&gt;</span> <span class="n">kernel</span><span class="p">(</span><span class="n">gamma</span><span class="p">);</span> <span class="c1">// Gaussian kernel</span>
</pre></div>
</div>
<p>All kernels such as the <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_gaussian_rbf_kernel.html">GaussianRbfKernel</a> are derived from the
base class <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_abstract_kernel_function.html">AbstractKernelFunction</a>.</p>
<p>Our model is thus a kernel classifier, which is
a linear classifier in feature space:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">KernelClassifier</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span> <span class="n">kc</span><span class="p">;</span> <span class="c1">// (affine) linear function in kernel-induced feature space</span>
</pre></div>
</div>
<p>A <cite>KernelClassifier</cite> can be understood as an <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_classifier.html">Classifier</a> which converts the output
of a <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_kernel_expansion.html">KernelExpansion</a> to a class label by choosing the index of the maximum output.
The <cite>KernelExpansion</cite> specifies a model from
<span class="math notranslate">\(\mathcal H_k = {\text{span} \{k(x, \cdot) \,|\, x \in X\}}\)</span> or
<span class="math notranslate">\(\mathcal H_k^b = \{f = g + b\,|\, g \in \mathcal H_k, b\in \mathbb{R}\}\)</span>
depending on whether a bias is used or not.</p>
<p>Training the machine is done by:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">;</span>          <span class="c1">// regularization parameter</span>
<span class="kt">bool</span> <span class="n">bias</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>           <span class="c1">// use bias/offset parameter</span>

<span class="n">CSvmTrainer</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="o">&gt;</span> <span class="n">trainer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernel</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">C</span></code> denotes the regularization parameter (the SVM uses the 1-norm
penalty for target margin violations by default) and <cite>bias</cite> the inclusion of a bias term in the solver..
The Shark SVM training is inspired by <a class="reference internal" href="#changlin2011" id="id3">[ChangLin2011]</a>
but uses unique features <a class="reference internal" href="#glasmachersigel2006" id="id4">[GlasmachersIgel2006]</a>.</p>
<div class="admonition-configuring-the-trainer-further admonition">
<p class="first admonition-title">Configuring the trainer further:</p>
<p>The above lines construct a default SVM trainer with default
settings for the underlying quadratic programming optimization
task. In certain cases, the user may want more fine-grained
control over the behaviour of the optimizer. For example,
the memory cache size of the kernel matrix cache and the
stopping criterion for the solver might be varied. Consider
the following lines of code:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
        <span class="c1">//to use &quot;double&quot; as kernel matrix cache type internally instead of float:</span>
        <span class="n">CSvmTrainer</span><span class="o">&lt;</span><span class="n">RealVector</span><span class="p">,</span> <span class="kt">double</span><span class="o">&gt;</span> <span class="n">trainer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernel</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">bias</span><span class="p">);</span>
        <span class="c1">//to keep non-support vectors after training:</span>
        <span class="n">trainer</span><span class="p">.</span><span class="n">sparsify</span><span class="p">()</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
        <span class="c1">//to relax or tighten the stopping criterion from 1e-3 (here, tightened to 1e-6)</span>
        <span class="n">trainer</span><span class="p">.</span><span class="n">stoppingCondition</span><span class="p">().</span><span class="n">minAccuracy</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">;</span>
        <span class="c1">//to set the cache size to 128MB for double (16**6 times sizeof(double), when double was selected as cache type above)</span>
        <span class="c1">//or to 64MB for float (16**6 times sizeof(float), when the CSvmTrainer is declared without second template argument)</span>
        <span class="n">trainer</span><span class="p">.</span><span class="n">setCacheSize</span><span class="p">(</span> <span class="mh">0x1000000</span> <span class="p">);</span>
        <span class="n">trainer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">kc</span><span class="p">,</span> <span class="n">training</span><span class="p">);</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;Needed &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">trainer</span><span class="p">.</span><span class="n">solutionProperties</span><span class="p">().</span><span class="n">seconds</span> <span class="o">&lt;&lt;</span> <span class="s">&quot; seconds to reach a dual of &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">trainer</span><span class="p">.</span><span class="n">solutionProperties</span><span class="p">().</span><span class="n">value</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p class="last">The first line uses one more template parameter in this alternative
trainer declaration, requesting it to use <code class="docutils literal notranslate"><span class="pre">double</span></code> for the matrix
cache internally (instead of the default <code class="docutils literal notranslate"><span class="pre">float</span></code>). Note that this
is only needed in very rare, mathematically sensitive cases.
The second line sets the trainer to <em>not</em> discard non-support
vectors from the solution kernel expansion after training
(they are discarded by default). The third line sets the desired
accuracy to a lower value (i.e., more strict value, implying longer
optimization times) than the default of 1e-3. The fourth
line reduces the cache size (counted in numbers of stored
variables of the matrix cache type) from 512MB to 128MB (had we
not passed the second template argument in the first line of this
snippet, it would be a reduction from 256MB to 64MB). The fifth
line is again identical to the above example. The last line
illustrates the use of the <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_qp_config.html#abf0512955ab98986c60e3c7627fa099d">solutionProperties()</a> method
to access information about the optimization run after training.
For more information on available options, see the documentation
of <a class="reference external" href="../../../../../../doxygen_pages/html/classshark_1_1_abstract_svm_trainer.html">AbstractSvmTrainer</a>, <a class="reference external" href="../../../../../../doxygen_pages/html/structshark_1_1_qp_stopping_condition.html">QpStoppingCondition</a>,
and <a class="reference external" href="../../../../../../doxygen_pages/html/structshark_1_1_qp_solution_properties.html">QpSolutionProperties</a> (as well as potentially of
the particular SVM solver you are using, i.e., binary, multi-class,
one-class, etc.).</p>
</div>
</div>
<div class="section" id="evaluating-the-model">
<h3>Evaluating the model<a class="headerlink" href="#evaluating-the-model" title="Permalink to this headline">¶</a></h3>
<p>After training the model, we can evaluate it.  As a performance
measure, we consider the standard 0-1 loss <span class="math notranslate">\(L_{0-1}(y,z)\)</span>
which we apply to training and test data:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">ZeroOneLoss</span><span class="o">&lt;</span><span class="kt">unsigned</span> <span class="kt">int</span><span class="o">&gt;</span> <span class="n">loss</span><span class="p">;</span> <span class="c1">// 0-1 loss</span>
<span class="n">Data</span><span class="o">&lt;</span><span class="kt">unsigned</span> <span class="kt">int</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">kc</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">inputs</span><span class="p">());</span> <span class="c1">// evaluate on training set</span>
<span class="kt">double</span> <span class="n">train_error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="n">eval</span><span class="p">(</span><span class="n">training</span><span class="p">.</span><span class="n">labels</span><span class="p">(),</span> <span class="n">output</span><span class="p">);</span>
<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;training error:</span><span class="se">\t</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span>  <span class="n">train_error</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">kc</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">inputs</span><span class="p">());</span> <span class="c1">// evaluate on test set</span>
<span class="kt">double</span> <span class="n">test_error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="n">eval</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">labels</span><span class="p">(),</span> <span class="n">output</span><span class="p">);</span>
<span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;test error:</span><span class="se">\t</span><span class="s">&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">test_error</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="full-example-program">
<h2>Full example program<a class="headerlink" href="#full-example-program" title="Permalink to this headline">¶</a></h2>
<p>The full example program considered in this tutorial is <a class="reference external" href="../../../../../../doxygen_pages/html/_c_svm_tutorial_8cpp.html">CSvmTutorial.cpp</a>.
Another relevant example in the <code class="docutils literal notranslate"><span class="pre">examples</span></code> subdirectory is the SVM
model selection (see the next tutorial on <a class="reference internal" href="svmModelSelection.html"><span class="doc">Support Vector Machines: Model Selection Using Cross-Validation and Grid-Search</span></a>);</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<table class="docutils citation" frame="void" id="changlin2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[ChangLin2011]</a></td><td>C.C. Chang and C.-J. Lin. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="cortesvapnik1995" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[CortesVapnik1995]</td><td><em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id2">2</a>)</em> C. Cortes and V. Vapnik. Support-Vector
Networks. Machine Learning, 20, 1995.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="glasmachersigel2006" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[GlasmachersIgel2006]</a></td><td><ol class="first last upperalpha simple" start="20">
<li>Glasmachers and C. Igel. Maximum-Gain Working Set Selection for SVMs. Journal of Machine Learning Research 7, 1437-1466, 2006.</li>
</ol>
</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
        <div class="footerlogos">
            <a href="http://validator.w3.org/check/referer" title="Valid XHTML 1.0">
                <img class="footerlogos" src="../../../_static/xhtml_validation.png" alt="Valid XHTML 1.0" />
            </a>
            <a href="http://jigsaw.w3.org/css-validator/check/referer?profile=css3" title="Valid CSS3">
                <img class="footerlogos" src="../../../_static/css_validation.png" alt="Valid CSS3" />
            </a>
        </div>
            &copy; The Shark developer team.
           Created on 09/06/2018
           using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.7.2
    </div>
  </body>
</html>